{"cells":[{"cell_type":"markdown","id":"056e1486-049e-4c00-bfbe-34b2b5358919","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/IDSN-logo.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"98c2d6d1-dfb6-4784-a8e6-af10e9105866","metadata":{},"source":["# **Introduction to DataFrames**\n"]},{"cell_type":"markdown","id":"a016b3af-3236-44d8-ae3e-5c1635a9ddff","metadata":{},"source":["Estimated time needed: **15** minutes\n"]},{"cell_type":"markdown","id":"f649ae31-7ba0-4c2d-a1a0-943462b4c7fb","metadata":{},"source":["![](http://spark.apache.org/images/spark-logo.png)\n"]},{"cell_type":"markdown","id":"9d8fc45f-d311-49a4-8f50-257bde0b8be7","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","id":"edd92436-7de4-48e3-88e9-0b8b9e6ba5de","metadata":{},"source":["A DataFrame is two-dimensional. Columns can be of different data types. DataFrames accept many data inputs including series and other DataFrames. You can pass indexes (row labels) and columns (column labels). Indexes can be numbers, dates, or strings/tuples.\n","\n","After completing this lab you will be able to:\n"]},{"cell_type":"markdown","id":"ae14f59d-5e3f-47bf-a501-fb98ed643590","metadata":{},"source":["* Load a data file into a DataFrame\n","* View the data schema of a DataFrame\n","* Perform basic data manipulation\n","* Aggregate data in a DataFrame\n"]},{"cell_type":"markdown","id":"9049f71c-bbe7-4826-a88d-80fb00594e51","metadata":{},"source":["----\n"]},{"cell_type":"markdown","id":"8fb8f019-f3e7-4a13-bb72-3f3648ea9795","metadata":{},"source":["## Setup\n"]},{"cell_type":"markdown","id":"297b534d-0e76-4684-b237-72626c8af438","metadata":{},"source":["For this lab, we are going to be using Python and Spark (PySpark). These libraries should be installed in your lab environment or in SN Labs.\n"]},{"cell_type":"markdown","id":"222408ce-d95c-4697-83be-f543becf16aa","metadata":{},"source":["Pandas is a popular data science package for Python. In this lab, we use Pandas to load a CSV file from disc to a pandas dataframe in memory. PySpark is the Spark API for Python. In this lab, we use PySpark to initialize the spark context.\n"]},{"cell_type":"code","execution_count":null,"id":"70f317c3-b82a-4ee4-81b1-144c2b42b8a3","metadata":{},"outputs":[],"source":["# Installing required packages\n","# !pip install pyspark\n","# !pip install findspark\n","# !pip install pandas"]},{"cell_type":"code","execution_count":1,"id":"6a4e08bf-bbcd-4b60-a357-d29c5e3c972d","metadata":{},"outputs":[],"source":["import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":2,"id":"560ea5c8-5cc9-4dc8-9c42-cf2d4aebf32b","metadata":{},"outputs":[],"source":["import pandas as pd\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SparkSession"]},{"cell_type":"markdown","id":"630fd601-445c-4f3f-99e6-dacf398396b2","metadata":{},"source":["## Exercise 1 -  Spark session\n"]},{"cell_type":"markdown","id":"d72ab0b3-96e2-437e-be71-85afd7039930","metadata":{},"source":["In this exercise, you will create and initialize the Spark session needed to load the dataframes and operate on it\n"]},{"cell_type":"markdown","id":"029a80bf-1ca4-4cb6-b20c-d4cc95299059","metadata":{},"source":["#### Task 1: Creating the spark session and context\n"]},{"cell_type":"code","execution_count":3,"id":"51aee059-1a44-4424-a7cf-e6db4d5230da","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["your 131072x1 screen size is bogus. expect trouble\n","24/04/11 19:55:58 WARN Utils: Your hostname, DESKTOP-LMLK3KO resolves to a loopback address: 127.0.1.1; using 172.19.128.203 instead (on interface eth0)\n","24/04/11 19:55:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/04/11 19:56:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------\n","Exception occurred during processing of request from ('127.0.0.1', 58158)\n","Traceback (most recent call last):\n","  File \"/home/hoon/.asdf/installs/python/3.12.2/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n","    self.process_request(request, client_address)\n","  File \"/home/hoon/.asdf/installs/python/3.12.2/lib/python3.12/socketserver.py\", line 349, in process_request\n","    self.finish_request(request, client_address)\n","  File \"/home/hoon/.asdf/installs/python/3.12.2/lib/python3.12/socketserver.py\", line 362, in finish_request\n","    self.RequestHandlerClass(request, client_address, self)\n","  File \"/home/hoon/.asdf/installs/python/3.12.2/lib/python3.12/socketserver.py\", line 761, in __init__\n","    self.handle()\n","  File \"/home/hoon/.cache/pypoetry/virtualenvs/ibm-ds-course-qjgZIpBq-py3.12/lib/python3.12/site-packages/pyspark/accumulators.py\", line 295, in handle\n","    poll(accum_updates)\n","  File \"/home/hoon/.cache/pypoetry/virtualenvs/ibm-ds-course-qjgZIpBq-py3.12/lib/python3.12/site-packages/pyspark/accumulators.py\", line 267, in poll\n","    if self.rfile in r and func():\n","                           ^^^^^^\n","  File \"/home/hoon/.cache/pypoetry/virtualenvs/ibm-ds-course-qjgZIpBq-py3.12/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n","    num_updates = read_int(self.rfile)\n","                  ^^^^^^^^^^^^^^^^^^^^\n","  File \"/home/hoon/.cache/pypoetry/virtualenvs/ibm-ds-course-qjgZIpBq-py3.12/lib/python3.12/site-packages/pyspark/serializers.py\", line 596, in read_int\n","    raise EOFError\n","EOFError\n","----------------------------------------\n"]}],"source":["\n","# Creating a spark session\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Python Spark DataFrames basic example\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()"]},{"cell_type":"markdown","id":"841afc81-f9c3-420d-b4f3-b4ab85b5f869","metadata":{},"source":["This will give an output similar to:\n","\n","```\n","23/10/17 08:29:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","```\n"]},{"cell_type":"markdown","id":"de14d8b5-08be-4a71-8d4e-725689074500","metadata":{},"source":["#### Task 2: Initialize Spark session\n","To work with dataframes we just need to verify that the spark session instance has been created.\n"]},{"cell_type":"code","execution_count":4,"id":"cb2234b5-f42a-4abf-ace0-900b0104236d","metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://172.19.128.203:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Python Spark DataFrames basic example</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fe62f1f6de0>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"markdown","id":"6844e908-882a-494d-9779-48596804520b","metadata":{},"source":["## Exercise 2 - Load the data and Spark dataframe\n"]},{"cell_type":"markdown","id":"321dbe0c-f889-417c-bc2f-fccf3e727b8e","metadata":{},"source":["In this section, you will first read the CSV file into a Pandas DataFrame and then read it into a Spark DataFrame.\n","Pandas is a library used for data manipulation and analysis. Pandas offers data structures and operations for creating and manipulating Data Series and DataFrame objects. Data can be imported from various data sources, e.g., Numpy arrays, Python dictionaries, and CSV files. Pandas allows you to manipulate, organize and display the data.\n","To create a Spark DataFrame we load an external DataFrame, called mtcars. This DataFrame includes 32 observations on 11 variables:\n","\n","\n","| colIndex | colName | units/description |\n","| :---: | :--- | :--- |\n","|[, 1] | mpg |Miles per gallon  |\n","|[, 2] | cyl | Number of cylinders  |\n","|[, 3] | disp | Displacement (cu.in.) |  \n","|[, 4] | hp  | Gross horsepower  |\n","|[, 5] | drat | Rear axle ratio  |\n","|[, 6] | wt | Weight (lb/1000)  |\n","|[, 7] | qsec | 1/4 mile time  |\n","|[, 8] | vs  | V/S  |\n","|[, 9] | am | Transmission (0 = automatic, 1 = manual)  |\n","|[,10] | gear | Number of forward gears  |\n","|[,11] | carb | Number of carburetors |\n"]},{"cell_type":"markdown","id":"8b1b1c2c-420d-4e7e-ad4a-00ac73589934","metadata":{},"source":["#### Task 1: Loading data into a Pandas DataFrame\n"]},{"cell_type":"code","execution_count":5,"id":"780310d5-6a12-452b-a7d2-90fe6a0daf56","metadata":{},"outputs":[],"source":["# Read the file using `read_csv` function in pandas\n","mtcars = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/mtcars.csv')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["(32, 12)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["mtcars.shape"]},{"cell_type":"code","execution_count":6,"id":"d1f8cd38-8ab7-4387-a2f7-c72e6bdbac8e","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>mpg</th>\n","      <th>cyl</th>\n","      <th>disp</th>\n","      <th>hp</th>\n","      <th>drat</th>\n","      <th>wt</th>\n","      <th>qsec</th>\n","      <th>vs</th>\n","      <th>am</th>\n","      <th>gear</th>\n","      <th>carb</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Mazda RX4</td>\n","      <td>21.0</td>\n","      <td>6</td>\n","      <td>160.0</td>\n","      <td>110</td>\n","      <td>3.90</td>\n","      <td>2.620</td>\n","      <td>16.46</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Mazda RX4 Wag</td>\n","      <td>21.0</td>\n","      <td>6</td>\n","      <td>160.0</td>\n","      <td>110</td>\n","      <td>3.90</td>\n","      <td>2.875</td>\n","      <td>17.02</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Datsun 710</td>\n","      <td>22.8</td>\n","      <td>4</td>\n","      <td>108.0</td>\n","      <td>93</td>\n","      <td>3.85</td>\n","      <td>2.320</td>\n","      <td>18.61</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Hornet 4 Drive</td>\n","      <td>21.4</td>\n","      <td>6</td>\n","      <td>258.0</td>\n","      <td>110</td>\n","      <td>3.08</td>\n","      <td>3.215</td>\n","      <td>19.44</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hornet Sportabout</td>\n","      <td>18.7</td>\n","      <td>8</td>\n","      <td>360.0</td>\n","      <td>175</td>\n","      <td>3.15</td>\n","      <td>3.440</td>\n","      <td>17.02</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Unnamed: 0   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n","0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n","1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n","2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n","3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n","4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n","\n","   carb  \n","0     4  \n","1     4  \n","2     1  \n","3     1  \n","4     2  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Preview a few records\n","mtcars.head()"]},{"cell_type":"markdown","id":"75e113ab-5cb8-4aed-9b10-47580ee3cd37","metadata":{},"source":["#### Task 2: Loading data into a Spark DataFrame\n"]},{"cell_type":"code","execution_count":7,"id":"5ba03ac9-d24b-4e45-967a-598449e28416","metadata":{},"outputs":[],"source":["# We use the `createDataFrame` function to load the data into a spark dataframe\n","sdf = spark.createDataFrame(mtcars) "]},{"cell_type":"code","execution_count":8,"id":"20898820-c46e-42df-90e8-b2b2143160bf","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Unnamed: 0: string (nullable = true)\n"," |-- mpg: double (nullable = true)\n"," |-- cyl: long (nullable = true)\n"," |-- disp: double (nullable = true)\n"," |-- hp: long (nullable = true)\n"," |-- drat: double (nullable = true)\n"," |-- wt: double (nullable = true)\n"," |-- qsec: double (nullable = true)\n"," |-- vs: long (nullable = true)\n"," |-- am: long (nullable = true)\n"," |-- gear: long (nullable = true)\n"," |-- carb: long (nullable = true)\n","\n"]}],"source":["# Let us look at the schema of the loaded spark dataframe\n","sdf.printSchema()"]},{"cell_type":"markdown","id":"7f202007-828e-44b2-973d-e26c0bd002eb","metadata":{},"source":["## Exercise 3: Basic data analysis and manipulation\n","\n","In this section, we perform basic data analysis and manipulation. We start with previewing the data and then applying some filtering and columwise operations.\n"]},{"cell_type":"markdown","id":"6810ceff-76d4-4e15-98eb-72a0b7020a62","metadata":{},"source":["#### Task 1: Displays the content of the DataFrame \n","\n","We use the `show()` method for this. Here we preview the first 5 records. Compare it to a similar `head()` function in Pandas.\n"]},{"cell_type":"code","execution_count":9,"id":"4c32c5ba-9a19-4254-864a-4943265d894c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n","|       Unnamed: 0| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n","+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n","|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n","|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n","|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n","|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n","|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n","+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n","only showing top 5 rows\n","\n"]}],"source":["sdf.show(5)"]},{"cell_type":"markdown","id":"ddea31d5-a1c2-4401-b246-c2ad814a461f","metadata":{},"source":["We use the `select()` function to select a particular column of data. Here we show the `mpg` column.\n"]},{"cell_type":"code","execution_count":11,"id":"a5e1478d-29f3-4481-96da-622807a29078","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+\n","| mpg|\n","+----+\n","|21.0|\n","|21.0|\n","|22.8|\n","|21.4|\n","|18.7|\n","+----+\n","only showing top 5 rows\n","\n"]}],"source":["sdf.select('mpg').show(5)"]},{"cell_type":"markdown","id":"93ae166d-c6de-4ac5-86c9-a9c87d58ed47","metadata":{},"source":["#### Task 2: Filtering and Columnar operations\n","\n","Filtering and Column operations are important to select relevant data and apply useful transformations. \n"]},{"cell_type":"markdown","id":"b26e2524-be6f-4dd1-ba7f-25165e146b46","metadata":{},"source":["We first filter to only retain rows with mpg > 18. We use the `filter()` function for this. \n"]},{"cell_type":"code","execution_count":12,"id":"246f4943-0f12-4390-ac55-47bf8ab025d3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------+----+---+-----+---+----+----+-----+---+---+----+----+\n","| Unnamed: 0| mpg|cyl| disp| hp|drat|  wt| qsec| vs| am|gear|carb|\n","+-----------+----+---+-----+---+----+----+-----+---+---+----+----+\n","| Duster 360|14.3|  8|360.0|245|3.21|3.57|15.84|  0|  0|   3|   4|\n","|  Merc 280C|17.8|  6|167.6|123|3.92|3.44| 18.9|  1|  0|   4|   4|\n","| Merc 450SE|16.4|  8|275.8|180|3.07|4.07| 17.4|  0|  0|   3|   3|\n","| Merc 450SL|17.3|  8|275.8|180|3.07|3.73| 17.6|  0|  0|   3|   3|\n","|Merc 450SLC|15.2|  8|275.8|180|3.07|3.78| 18.0|  0|  0|   3|   3|\n","+-----------+----+---+-----+---+----+----+-----+---+---+----+----+\n","only showing top 5 rows\n","\n"]}],"source":["sdf.filter(sdf['mpg'] < 18).show(5)"]},{"cell_type":"markdown","id":"260f26c8-d2e5-46c7-8568-b3a83a0f813e","metadata":{},"source":["Operating on Columns\n","\n","Spark also provides a number of functions that can be directly applied to columns for data processing and aggregation. The example below shows the use of basic arithmetic functions to convert the weight values from `lb` to `metric ton`.\n","We create a new column called `wtTon` that has the weight from the `wt` column converted to metric tons. \n"]},{"cell_type":"code","execution_count":13,"id":"d9f33450-a3b8-43ef-9a2a-52b7b6ea508e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+-------+\n","|       Unnamed: 0| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|  wtTon|\n","+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+-------+\n","|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|  1.179|\n","|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|1.29375|\n","|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|  1.044|\n","|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|1.44675|\n","|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|  1.548|\n","+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+-------+\n","only showing top 5 rows\n","\n"]}],"source":["sdf.withColumn('wtTon', sdf['wt'] * 0.45).show(5)"]},{"cell_type":"markdown","id":"86551839-4d3b-41e6-a967-1c0a164b2ce7","metadata":{},"source":["#### Task 3: Rename the existing column name \"vs\" to \"versus\" and assign the new result DataFrame to a variable, \"sdf_new\". \n","\n","The function \"withColumnRenamed()\" renames the existing column names.  \n"]},{"cell_type":"code","execution_count":14,"id":"3d0094bd-8409-41b9-a4de-149cfac1c99f","metadata":{},"outputs":[],"source":["sdf_new = sdf.withColumnRenamed(\"vs\", \"versus\")"]},{"cell_type":"markdown","id":"da41acf1-f7ae-47bd-b223-4d3146b12d2b","metadata":{},"source":["The execution of the above function doesn’t modify the original DataFrame \"sdf\"; instead, a new DataFrame \"sdf_new\" is created with the renamed column. \n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+----+---+-----+---+----+-----+-----+------+---+----+----+\n","|       Unnamed: 0| mpg|cyl| disp| hp|drat|   wt| qsec|versus| am|gear|carb|\n","+-----------------+----+---+-----+---+----+-----+-----+------+---+----+----+\n","|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|     0|  1|   4|   4|\n","|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|     0|  1|   4|   4|\n","|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|     1|  1|   4|   1|\n","|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|     1|  0|   3|   1|\n","|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|     0|  0|   3|   2|\n","+-----------------+----+---+-----+---+----+-----+-----+------+---+----+----+\n","only showing top 5 rows\n","\n"]}],"source":["sdf_new.show(5)"]},{"cell_type":"markdown","id":"3512481d-d459-40d9-9465-35680cc55f65","metadata":{},"source":["#### Task 4: Filter the records based on the condition \n","\n","The function \"where()\" filters the Dataframe rows based on the given condition. It returns a new DataFrame containing the rows that satisfy the given condition. \n"]},{"cell_type":"code","execution_count":16,"id":"c5c23372-d7c1-44ff-9419-99176e9f5395","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+----+---+-----+---+----+----+-----+---+---+----+----+\n","|Unnamed: 0| mpg|cyl| disp| hp|drat|  wt| qsec| vs| am|gear|carb|\n","+----------+----+---+-----+---+----+----+-----+---+---+----+----+\n","|Duster 360|14.3|  8|360.0|245|3.21|3.57|15.84|  0|  0|   3|   4|\n","| Merc 280C|17.8|  6|167.6|123|3.92|3.44| 18.9|  1|  0|   4|   4|\n","|Merc 450SE|16.4|  8|275.8|180|3.07|4.07| 17.4|  0|  0|   3|   3|\n","+----------+----+---+-----+---+----+----+-----+---+---+----+----+\n","only showing top 3 rows\n","\n"]}],"source":["sdf.where(sdf['mpg'] < 18).show(3) "]},{"cell_type":"markdown","id":"432ad97b-15b3-44a9-a702-e1adfa3aa2cd","metadata":{},"source":[">Note: Both filter() and where() functions are used for the same purpose. \n"]},{"cell_type":"markdown","id":"6b46f514-37ed-4e27-846e-a147d49d83b9","metadata":{},"source":["#### Task 5: Combining DataFrames based on a specific condition. \n","\n","The function \"join()\"combines the DataFrames based on a specific condition. \n","\n","See the below examples.\n"]},{"cell_type":"code","execution_count":17,"id":"134dd131-b1b7-4f78-8583-8d3e91e0e0c7","metadata":{},"outputs":[],"source":["# define sample DataFrame 1 \n","\n","data = [(\"A101\", \"John\"), (\"A102\", \"Peter\"), (\"A103\", \"Charlie\")] \n","\n","columns = [\"emp_id\", \"emp_name\"] \n","\n","dataframe_1 = spark.createDataFrame(data, columns) "]},{"cell_type":"code","execution_count":18,"id":"d42a9373-85bb-4f7c-a28a-02bf8ad8593e","metadata":{},"outputs":[],"source":["# define sample DataFrame 2 \n","\n","data = [(\"A101\", 1000), (\"A102\", 2000), (\"A103\", 3000)]\n","\n","columns = [\"emp_id\", \"salary\"]\n","\n","dataframe_2 = spark.createDataFrame(data, columns)"]},{"cell_type":"code","execution_count":19,"id":"41bc8124-b66d-4768-b3db-d18f33c45c8c","metadata":{},"outputs":[],"source":["# create a new DataFrame, \"combined_df\" by performing an inner join\n","\n","combined_df = dataframe_1.join(dataframe_2, on=\"emp_id\", how=\"inner\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 13:==================================================>       (7 + 1) / 8]\r"]},{"name":"stdout","output_type":"stream","text":["+------+--------+------+\n","|emp_id|emp_name|salary|\n","+------+--------+------+\n","|  A101|    John|  1000|\n","|  A102|   Peter|  2000|\n","+------+--------+------+\n","only showing top 2 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["combined_df.show(2)"]},{"cell_type":"markdown","id":"10fdc197-d7c7-4fb9-b8af-16363441f328","metadata":{},"source":["#### Task 6: Filling the missing values \n","\n","\"fillna()\" or \"fill()\" function fill the missing values with a specified value. \n"]},{"cell_type":"code","execution_count":21,"id":"c67a16fb-0280-49c6-b6e1-f9f3b0502d04","metadata":{},"outputs":[],"source":["# define sample DataFrame 1\n","\n","data = [(\"A101\", 1000), (\"A102\", 2000), (\"A103\",None)]\n","\n","columns = [\"emp_id\", \"salary\"]\n","\n","dataframe_1 = spark.createDataFrame(data, columns)"]},{"cell_type":"markdown","id":"9c8ede96-3785-44b6-8c38-c3066562b487","metadata":{},"source":["Note that the third record of the DataFrame \"dataframe_1\", the column “salary”, contains null(\"na\") value. It can be filled with a value by using the function \"fillna()\". \n"]},{"cell_type":"code","execution_count":22,"id":"e467f535-1965-4d2d-ae8a-a1f02da879af","metadata":{},"outputs":[{"data":{"text/plain":["[Row(emp_id='A101', salary=1000),\n"," Row(emp_id='A102', salary=2000),\n"," Row(emp_id='A103', salary=3000)]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# fill missing salary value with a specified value \n","\n","filled_df = dataframe_1.fillna({\"salary\": 3000}) \n","filled_df.head(3)"]},{"cell_type":"markdown","id":"b0b0d2e0-6d37-45f6-ade1-5d41e0c7817a","metadata":{},"source":["## Exercise 4: Grouping and Aggregation\n","\n","Spark DataFrames support a number of commonly used functions to aggregate data after grouping. In this example we compute the average weight of cars by their cylinders as shown below.\n"]},{"cell_type":"code","execution_count":23,"id":"3853abb6-8548-4183-91d6-d6d778760fbb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----------------+\n","|cyl|          avg(wt)|\n","+---+-----------------+\n","|  6|3.117142857142857|\n","|  4|2.285727272727273|\n","|  8|3.999214285714286|\n","+---+-----------------+\n","\n"]}],"source":["sdf.groupby(['cyl'])\\\n",".agg({\"wt\": \"AVG\"})\\\n",".show(5)"]},{"cell_type":"markdown","id":"1802e890-6ecc-4b8f-b488-e20da59fe508","metadata":{},"source":["We can also sort the output from the aggregation to get the most common cars.\n"]},{"cell_type":"code","execution_count":24,"id":"fdf17bf0-38e3-40b5-a363-250230e09be6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+\n","|cyl|count(wt)|\n","+---+---------+\n","|  8|       14|\n","|  4|       11|\n","|  6|        7|\n","+---+---------+\n","\n"]}],"source":["car_counts = sdf.groupby(['cyl'])\\\n",".agg({\"wt\": \"count\"})\\\n",".sort(\"count(wt)\", ascending=False)\\\n",".show(5)\n"]},{"cell_type":"markdown","id":"e9444690-9f1b-4083-b9a5-23f77fbe2f32","metadata":{},"source":["## Practice Questions\n"]},{"cell_type":"markdown","id":"cfbf9472-2312-4ffa-a167-92d8e9cd386f","metadata":{},"source":["### Question 1 - DataFrame basics\n"]},{"cell_type":"markdown","id":"ec6efcc6-710d-4118-8e74-ee118b55d139","metadata":{},"source":["Display the first 5 rows of all cars that have atleast 5 cylinders.\n"]},{"cell_type":"code","execution_count":25,"id":"0cc5bb29-54e4-4dc8-9e15-9e50ad3ae8ed","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n","|       Unnamed: 0| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n","+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n","|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n","|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n","|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n","|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n","|          Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|\n","+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n","only showing top 5 rows\n","\n"]}],"source":["# Code block for learners to answer\n","sdf.where(sdf['cyl'] > 5).show(5)"]},{"cell_type":"markdown","id":"bdeaf721-283a-4f23-bc0c-f7349db13a7f","metadata":{},"source":["### Question 2 - DataFrame aggregation\n"]},{"cell_type":"markdown","id":"33be8ecb-bf37-42f1-ad25-238070480e7b","metadata":{},"source":["Using the functions and tables shown above, print out the mean weight of a car in our database in metric tons.\n"]},{"cell_type":"code","execution_count":33,"id":"c4f3f576-7602-4c55-a2c0-3c9f784bb2b1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+\n","|avg(wtTon)|\n","+----------+\n","| 1.4477625|\n","+----------+\n","\n"]}],"source":["# Code block for learners to answer\n","# sdf.withColumn('wtTon', sdf['wt'] * 0.45).groupby(['cyl']).agg({'wtTon': 'AVG'}).show()\n","sdf.withColumn('wtTon', sdf['wt'] * 0.45).agg({'wtTon': 'AVG'}).show()\n"]},{"cell_type":"markdown","id":"103261ca-ff9f-46a9-9ec2-c26ec179370b","metadata":{},"source":["### Question 3 - DataFrame columnar operations\n"]},{"cell_type":"markdown","id":"2ff6391a-12a3-4e75-be0b-174fd00afd0b","metadata":{},"source":["In the earlier sections of this notebook, we have created a new column called `wtTon` to indicate the weight in metric tons using a standard conversion formula. In this case we have applied this directly to the dataframe column `wt` as it is a linear operation (multiply by 0.45). Similarly, as part of this exercise, create a new column for mileage in `kmpl` (kilometer-per-liter) instead of `mpg`(miles-per-gallon) by using a conversion factor of 0.425.\n","\n","Additionally sort the output in decreasing order of mileage in kmpl.\n"]},{"cell_type":"code","execution_count":34,"id":"e1ba9db8-204a-42b6-9696-8c0deded5d2c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+------------------+\n","|       Unnamed: 0| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|              kmpl|\n","+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+------------------+\n","|   Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|14.407499999999999|\n","|         Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|             13.77|\n","|     Lotus Europa|30.4|  4| 95.1|113|3.77|1.513| 16.9|  1|  1|   5|   2|             12.92|\n","|      Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|             12.92|\n","|        Fiat X1-9|27.3|  4| 79.0| 66|4.08|1.935| 18.9|  1|  1|   4|   1|           11.6025|\n","|    Porsche 914-2|26.0|  4|120.3| 91|4.43| 2.14| 16.7|  0|  1|   5|   2|11.049999999999999|\n","|        Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|             10.37|\n","|         Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|              9.69|\n","|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|              9.69|\n","|    Toyota Corona|21.5|  4|120.1| 97| 3.7|2.465|20.01|  1|  0|   3|   1|            9.1375|\n","|       Volvo 142E|21.4|  4|121.0|109|4.11| 2.78| 18.6|  1|  1|   4|   2| 9.094999999999999|\n","|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1| 9.094999999999999|\n","|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4| 8.924999999999999|\n","|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4| 8.924999999999999|\n","|     Ferrari Dino|19.7|  6|145.0|175|3.62| 2.77| 15.5|  0|  1|   5|   6| 8.372499999999999|\n","|         Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|              8.16|\n","| Pontiac Firebird|19.2|  8|400.0|175|3.08|3.845|17.05|  0|  0|   3|   2|              8.16|\n","|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|            7.9475|\n","|          Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1| 7.692500000000001|\n","|        Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|             7.565|\n","+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["24/04/12 16:58:17 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 616911 ms exceeds timeout 120000 ms\n","24/04/12 16:58:17 WARN SparkContext: Killing executors is not supported by current scheduler.\n","24/04/12 16:58:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:58:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 16:59:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:00:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:01:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:02:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:03:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:04:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:05:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","24/04/12 17:06:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","24/04/12 17:06:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:06:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:18 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:18 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:28 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:28 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:38 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:38 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:48 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:48 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:58 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:07:58 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:08:08 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:08:08 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.128.203:40645\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","24/04/12 17:08:08 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"]}],"source":["# Code block for learners to answer\n","sdf.withColumn('kmpl', sdf['mpg'] * 0.425).sort('mpg', ascending=False).show()"]},{"cell_type":"markdown","id":"cd834156-4b98-453f-b844-3fd55deac108","metadata":{},"source":["Double-click **here** for a hint.\n","\n","<!-- The hint is below:\n","\n","1. Use the functions `withColumn()` to create a new column with a linear operation of an existing column. \n","2. Use the `sort()` function to order results.\n","\n","-->\n"]},{"cell_type":"markdown","id":"c3c1c226-456b-41cb-9c06-120ce7742960","metadata":{},"source":["Double-click **here** for the solution.\n","\n","<!-- The answer is below:\n","\n","sdf.withColumn('kmpl', sdf['mpg'] * 0.425).sort('mpg', ascending=False).show()\n","-->\n"]},{"cell_type":"markdown","id":"59d5ee9a-8e49-4d66-8a76-3bdcaa4a2151","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","id":"385b93a2-d24b-46aa-bd22-70fe5d398c16","metadata":{},"source":["[Karthik Muthuraman](https://www.linkedin.com/in/karthik-muthuraman/)\n"]},{"cell_type":"markdown","id":"d9cc79d6-ba50-4138-ad58-6d5bb7ec86a4","metadata":{},"source":["### Other Contributors\n"]},{"cell_type":"markdown","id":"3ccb4182-ca6c-4ec1-9d76-5d70b570add9","metadata":{},"source":["[Jerome Nilmeier](https://github.com/nilmeier)\n"]},{"cell_type":"markdown","id":"01108ade-8055-433f-a38b-4bf477e450d3","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","id":"3a95f7a2-f8ce-4d36-b7b4-68009ed54a97","metadata":{},"source":["|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n","|-|-|-|-|\n","|2023-10-17|0.3|K Sundararajan|Updated instructions based on Beta Testing|\n","|2021-07-02|0.2|Karthik|Beta launch|\n","|2021-06-30|0.1|Karthik|First Draft|\n"]},{"cell_type":"markdown","id":"9d023b56-fd3a-4a70-95ae-38401355761f","metadata":{},"source":["Copyright © 2023 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"ibm-ds-course-qjgZIpBq-py3.12","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
